#!/usr/bin/env python3
"""
Comprehensive Enhanced Columns Test Suite

Tests the complete refactored column processing architecture including:
- PyPI data columns (E-J including new H)
- GitHub analysis columns (K-M) 
- Vulnerability database columns (O-V) with AI sandboxes
- Sophisticated recommendation column (W)

Based on deep analysis of retired version's approach with our AI infrastructure.
"""

import asyncio
import sys
import json
from pathlib import Path
from typing import Dict, Any
import logging

# Add src to path
sys.path.insert(0, str(Path(__file__).parent / "src"))

from src.integrations.enhanced_column_orchestrator import EnhancedColumnOrchestrator
from src.core.ai_analyzer import AIAnalyzer
from src.core.sandbox_manager import SandboxManager
from src.config import ConfigManager


async def test_comprehensive_columns(package_name: str, version: str):
    """Test all enhanced columns with the new architecture."""
    print(f"\n{'='*100}")
    print(f"ğŸ”¬ COMPREHENSIVE ENHANCED COLUMNS TEST")
    print(f"{'='*100}")
    print(f"ğŸ“¦ Package: {package_name} v{version}")
    print(f"ğŸ—ï¸  Architecture: Retired Version Analysis + AI Sandboxes")
    print(f"{'='*100}")
    
    try:
        # Load configuration
        config_manager = ConfigManager()
        config = config_manager.load_config()
        print(f"âœ… Configuration loaded successfully")
        
        # Initialize AI analyzer
        ai_analyzer = AIAnalyzer(config.ai.__dict__ if hasattr(config, 'ai') else {})
        print(f"âœ… AI analyzer initialized: {ai_analyzer.__class__.__name__}")
        
        # Initialize sandbox manager
        config_dict = config.__dict__ if hasattr(config, '__dict__') else config
        sandbox_manager = SandboxManager(config_dict)
        await sandbox_manager.initialize()  # This is crucial - it registers all sandboxes
        print(f"âœ… Sandbox manager initialized with AI sandboxes")
        
        # Initialize enhanced column orchestrator
        orchestrator = EnhancedColumnOrchestrator(
            config=config,
            ai_analyzer=ai_analyzer,
            sandbox_manager=sandbox_manager
        )
        print(f"âœ… Enhanced column orchestrator initialized")
        print()
        
        # Process all columns comprehensively
        print(f"ğŸš€ Starting comprehensive column processing...")
        print(f"   This will test ALL columns A-W with the new architecture")
        print()
        
        start_time = asyncio.get_event_loop().time()
        results = await orchestrator.process_all_columns(package_name, version)
        end_time = asyncio.get_event_loop().time()
        
        processing_time = end_time - start_time
        print(f"â±ï¸  Total processing time: {processing_time:.2f} seconds")
        print()
        
        # Display results by category
        await display_results_by_category(results, package_name, version)
        
        # Save detailed results
        output_file = f"comprehensive_test_results_{package_name}_{version.replace('.', '_')}.json"
        with open(output_file, 'w') as f:
            json.dump(results, f, indent=2, default=str)
        print(f"ğŸ’¾ Detailed results saved to: {output_file}")
        
        # Cleanup
        await orchestrator.cleanup()
        print(f"âœ… Cleanup completed")
        
    except Exception as e:
        print(f"âŒ Comprehensive test failed: {e}")
        import traceback
        traceback.print_exc()


async def display_results_by_category(results: Dict[str, Any], package_name: str, version: str):
    """Display results organized by functional category."""
    
    print(f"ğŸ“Š COMPREHENSIVE RESULTS FOR {package_name} v{version}")
    print(f"{'='*100}")
    
    # Category 1: PyPI Package Data (E-J)
    print(f"\nğŸ“¦ PYPI PACKAGE DATA (Columns E-J)")
    print(f"{'â”€'*60}")
    pypi_columns = {
        'E': 'Date Published (Current Version)',
        'F': 'Latest Version Available', 
        'H': 'Latest Version Release Date âœ¨ NEW',
        'I': 'Requirements/Dependencies',
        'J': 'Development Status'
    }
    
    for col, description in pypi_columns.items():
        if col in results:
            result = results[col]
            status = "âœ…" if result.get('color') != 'critical' else "âŒ"
            print(f"  {status} Column {col}: {description}")
            print(f"     Value: {result.get('value', 'N/A')}")
            print(f"     Note:  {result.get('note', 'N/A')}")
            print()
    
    # Category 2: GitHub Integration (K-M)
    print(f"\nğŸ™ GITHUB INTEGRATION (Columns K-M)")
    print(f"{'â”€'*60}")
    github_columns = {
        'K': 'GitHub Repository URL',
        'L': 'GitHub Security Advisories URL',
        'M': 'GitHub Security Analysis Result'
    }
    
    for col, description in github_columns.items():
        if col in results:
            result = results[col]
            status = "âœ…" if result.get('color') != 'critical' else "âŒ"
            print(f"  {status} Column {col}: {description}")
            print(f"     Value: {result.get('value', 'N/A')}")
            print(f"     Note:  {result.get('note', 'N/A')}")
            print()
    
    # Category 3: AI-Powered Vulnerability Scanning (O-V)
    print(f"\nğŸ¤– AI-POWERED VULNERABILITY SCANNING (Columns O-V)")
    print(f"{'â”€'*60}")
    vuln_columns = {
        'O': 'NIST NVD Search URL',
        'P': 'NIST NVD Scan Result (AI Enhanced)',
        'Q': 'MITRE CVE Search URL', 
        'R': 'MITRE CVE Scan Result (AI Enhanced)',
        'S': 'SNYK Vulnerability Search URL',
        'T': 'SNYK Vulnerability Scan Result (AI Enhanced)',
        'U': 'Exploit Database Search URL',
        'V': 'Exploit Database Scan Result (AI Enhanced)'
    }
    
    for col, description in vuln_columns.items():
        if col in results:
            result = results[col]
            status = "âœ…" if result.get('color') != 'critical' else "âŒ"
            ai_marker = "ğŸ¤–" if 'AI' in description else "ğŸ”—"
            print(f"  {status} {ai_marker} Column {col}: {description}")
            print(f"     Value: {result.get('value', 'N/A')}")
            print(f"     Note:  {result.get('note', 'N/A')}")
            if result.get('vulnerability_count'):
                print(f"     Vulnerabilities: {result.get('vulnerability_count')} found")
            print()
    
    # Category 4: AI-Enhanced Recommendation (W)
    print(f"\nğŸ§  AI-ENHANCED COMPREHENSIVE RECOMMENDATION (Column W)")
    print(f"{'â”€'*60}")
    if 'W' in results:
        recommendation = results['W']
        status = "âœ…" if recommendation.get('color') != 'critical' else "âš ï¸" if recommendation.get('color') == 'security_risk' else "âœ…"
        print(f"  {status} Column W: IHACPA Comprehensive Recommendation")
        print(f"     Recommendation: {recommendation.get('value', 'N/A')}")
        print(f"     Analysis Note:  {recommendation.get('note', 'N/A')}")
        print(f"     Tier Level:     {recommendation.get('recommendation_tier', 'N/A')}")
        print(f"     AI Enhanced:    {recommendation.get('ai_enhanced', False)}")
        
        # Show classification summary
        if 'classification_summary' in recommendation:
            classifications = recommendation['classification_summary']
            print(f"     Classification Summary:")
            for category, items in classifications.items():
                if items:
                    print(f"       - {category.title()}: {len(items)} databases")
        print()
    
    # Summary Statistics
    print(f"\nğŸ“ˆ PROCESSING SUMMARY")
    print(f"{'â”€'*60}")
    
    total_columns = len(results)
    successful_columns = sum(1 for r in results.values() if r.get('color') != 'critical')
    error_columns = total_columns - successful_columns
    
    print(f"  ğŸ“Š Total Columns Processed: {total_columns}")
    print(f"  âœ… Successful Columns:     {successful_columns}")
    print(f"  âŒ Error Columns:          {error_columns}")
    print(f"  ğŸ¯ Success Rate:           {(successful_columns/total_columns)*100:.1f}%")
    
    # Vulnerability Summary
    vuln_counts = {}
    for col in ['P', 'R', 'T', 'V']:
        if col in results and results[col].get('vulnerability_count'):
            vuln_counts[col] = results[col]['vulnerability_count']
    
    if vuln_counts:
        print(f"\nğŸ” VULNERABILITY SUMMARY")
        print(f"{'â”€'*60}")
        total_vulns = sum(vuln_counts.values())
        print(f"  ğŸš¨ Total Vulnerabilities Found: {total_vulns}")
        for col, count in vuln_counts.items():
            db_name = {'P': 'NIST NVD', 'R': 'MITRE CVE', 'T': 'SNYK', 'V': 'Exploit DB'}[col]
            print(f"     - {db_name}: {count}")


async def main():
    """Main test function."""
    print("ğŸ§ª IHACPA v2.0 - Comprehensive Enhanced Columns Test Suite")
    print("ğŸ”¬ Testing Complete Architecture: Retired Version Analysis + AI Sandboxes")
    print("ğŸ“‹ Coverage: ALL columns A-W with sophisticated processing")
    print()
    
    # Test packages
    test_packages = [
        ("requests", "2.28.1"),
        ("flask", "2.0.0"),
        ("urllib3", "1.26.0"),
        ("django", "3.0.0")
    ]
    
    # Allow user to specify package
    if len(sys.argv) >= 3:
        package_name = sys.argv[1]
        version = sys.argv[2]
        test_packages = [(package_name, version)]
        print(f"ğŸ¯ Testing user-specified package: {package_name} v{version}")
    elif len(sys.argv) == 2:
        package_name = sys.argv[1]
        version = "latest"
        test_packages = [(package_name, version)]
        print(f"ğŸ¯ Testing user-specified package: {package_name} (latest version)")
    else:
        print(f"ğŸ§ª Testing default package set: {len(test_packages)} packages")
    
    print()
    
    # Run comprehensive tests
    for package_name, version in test_packages:
        await test_comprehensive_columns(package_name, version)
        
        # Small delay between packages if testing multiple
        if len(test_packages) > 1:
            print(f"\nâ³ Waiting 2 seconds before next package...")
            await asyncio.sleep(2)
    
    print(f"\nğŸ‰ Comprehensive Enhanced Columns Test Suite Completed!")
    print(f"ğŸ—ï¸  Architecture successfully validated with {len(test_packages)} package(s)")


if __name__ == '__main__':
    # Setup logging for better debugging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    asyncio.run(main())