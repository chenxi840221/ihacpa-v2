"""
Exploit Database Models

Models for Exploit-DB responses and AI-enhanced threat analysis.
"""

from dataclasses import dataclass
from typing import List, Optional, Dict, Any
from datetime import datetime
from enum import Enum

from ...core.base_scanner import SeverityLevel


class ExploitType(Enum):
    """Exploit type categories"""
    REMOTE = "remote"
    LOCAL = "local"
    WEB = "webapps"
    DOS = "dos"
    MULTIPLE = "multiple"
    UNKNOWN = "unknown"


class ExploitPlatform(Enum):
    """Target platforms"""
    LINUX = "linux"
    WINDOWS = "windows"
    MACOS = "macos"
    MULTIPLE = "multiple"
    HARDWARE = "hardware"
    UNKNOWN = "unknown"


class ThreatLevel(Enum):
    """AI-assessed threat levels"""
    CRITICAL = "critical"
    HIGH = "high"
    MEDIUM = "medium"
    LOW = "low"
    INFORMATIONAL = "informational"


@dataclass
class ExploitDBEntry:
    """
    Exploit-DB entry with AI-enhanced threat analysis.
    """
    edb_id: str
    title: str
    description: str
    exploit_type: ExploitType = ExploitType.UNKNOWN
    platform: ExploitPlatform = ExploitPlatform.UNKNOWN
    
    # Publication information
    date_published: Optional[datetime] = None
    author: Optional[str] = None
    
    # Technical details
    cve_ids: List[str] = None
    tags: List[str] = None
    verified: bool = False
    
    # Exploit characteristics
    code_language: Optional[str] = None
    exploit_code: Optional[str] = None
    file_url: Optional[str] = None
    
    # Target information
    application: Optional[str] = None
    version: Optional[str] = None
    vendor: Optional[str] = None
    
    # AI Enhancement fields
    ai_threat_level: Optional[ThreatLevel] = None
    ai_exploitability_score: Optional[float] = None
    ai_confidence: Optional[float] = None
    ai_relevance_score: Optional[float] = None
    ai_threat_analysis: Optional[str] = None
    ai_attack_vector_analysis: Optional[str] = None
    ai_impact_assessment: Optional[str] = None
    ai_mitigation_recommendations: List[str] = None
    ai_ioc_indicators: List[str] = None  # Indicators of Compromise
    ai_related_techniques: List[str] = None  # MITRE ATT&CK techniques
    
    def __post_init__(self):
        if self.cve_ids is None:
            self.cve_ids = []
        if self.tags is None:
            self.tags = []
        if self.ai_mitigation_recommendations is None:
            self.ai_mitigation_recommendations = []
        if self.ai_ioc_indicators is None:
            self.ai_ioc_indicators = []
        if self.ai_related_techniques is None:
            self.ai_related_techniques = []
    
    def get_severity_from_threat_level(self) -> SeverityLevel:
        """Convert AI threat level to standard severity"""
        if self.ai_threat_level == ThreatLevel.CRITICAL:
            return SeverityLevel.CRITICAL
        elif self.ai_threat_level == ThreatLevel.HIGH:
            return SeverityLevel.HIGH
        elif self.ai_threat_level == ThreatLevel.MEDIUM:
            return SeverityLevel.MEDIUM
        elif self.ai_threat_level == ThreatLevel.LOW:
            return SeverityLevel.LOW
        else:
            return SeverityLevel.INFO
    
    def is_remote_exploit(self) -> bool:
        """Check if this is a remote exploit"""
        return self.exploit_type in [ExploitType.REMOTE, ExploitType.WEB]
    
    def is_verified_exploit(self) -> bool:
        """Check if this exploit is verified"""
        return self.verified or self.ai_confidence and self.ai_confidence >= 0.8
    
    def get_attack_complexity(self) -> str:
        """Assess attack complexity based on exploit characteristics"""
        if self.ai_exploitability_score:
            if self.ai_exploitability_score >= 0.8:
                return "Low"
            elif self.ai_exploitability_score >= 0.5:
                return "Medium"
            else:
                return "High"
        
        # Fallback based on exploit type
        if self.exploit_type == ExploitType.REMOTE:
            return "Low"
        elif self.exploit_type == ExploitType.WEB:
            return "Medium"
        else:
            return "High"
    
    def to_base_vulnerability(self):
        """Convert to base VulnerabilityInfo format"""
        from ...core.base_scanner import VulnerabilityInfo, ConfidenceLevel
        
        # Determine severity
        severity = self.get_severity_from_threat_level()
        
        # Determine confidence
        confidence = ConfidenceLevel.MEDIUM
        if self.ai_confidence:
            if self.ai_confidence >= 0.9:
                confidence = ConfidenceLevel.VERY_HIGH
            elif self.ai_confidence >= 0.75:
                confidence = ConfidenceLevel.HIGH
            elif self.ai_confidence >= 0.5:
                confidence = ConfidenceLevel.MEDIUM
            elif self.ai_confidence >= 0.25:
                confidence = ConfidenceLevel.LOW
            else:
                confidence = ConfidenceLevel.VERY_LOW
        elif self.verified:
            confidence = ConfidenceLevel.HIGH
        
        # Create enhanced description
        description = self.description
        if self.ai_threat_analysis:
            description += f"\n\nThreat Analysis: {self.ai_threat_analysis}"
        if self.ai_attack_vector_analysis:
            description += f"\n\nAttack Vector: {self.ai_attack_vector_analysis}"
        if self.ai_impact_assessment:
            description += f"\n\nImpact Assessment: {self.ai_impact_assessment}"
        if self.ai_mitigation_recommendations:
            mitigations = "\n".join([f"â€¢ {rec}" for rec in self.ai_mitigation_recommendations])
            description += f"\n\nMitigation Recommendations:\n{mitigations}"
        
        # Add technical details
        if self.exploit_type != ExploitType.UNKNOWN:
            description += f"\n\nExploit Type: {self.exploit_type.value}"
        if self.platform != ExploitPlatform.UNKNOWN:
            description += f"\nTarget Platform: {self.platform.value}"
        if self.code_language:
            description += f"\nExploit Language: {self.code_language}"
        
        return VulnerabilityInfo(
            cve_id=self.cve_ids[0] if self.cve_ids else None,
            title=f"Exploit Available: {self.title}",
            description=description,
            severity=severity,
            confidence=confidence,
            published_date=self.date_published,
            references=[self.file_url] if self.file_url else [],
            source_url=f"https://www.exploit-db.com/exploits/{self.edb_id}"
        )


@dataclass
class ExploitDBThreatIntel:
    """
    Aggregated threat intelligence from Exploit-DB analysis.
    """
    target_package: str
    search_query: str
    total_exploits: int
    
    # Exploit analysis
    exploits: List[ExploitDBEntry] = None
    
    # AI-generated threat intelligence
    ai_overall_threat_level: Optional[ThreatLevel] = None
    ai_threat_landscape: Optional[str] = None
    ai_exploit_trends: Optional[str] = None
    ai_attack_patterns: List[str] = None
    ai_defensive_recommendations: List[str] = None
    ai_monitoring_recommendations: List[str] = None
    ai_priority_exploits: List[str] = None  # EDB IDs ranked by priority
    
    # Statistical analysis
    exploit_type_distribution: Dict[str, int] = None
    platform_distribution: Dict[str, int] = None
    temporal_distribution: Dict[str, int] = None  # Exploits by year
    verification_rate: float = 0.0
    
    def __post_init__(self):
        if self.exploits is None:
            self.exploits = []
        if self.ai_attack_patterns is None:
            self.ai_attack_patterns = []
        if self.ai_defensive_recommendations is None:
            self.ai_defensive_recommendations = []
        if self.ai_monitoring_recommendations is None:
            self.ai_monitoring_recommendations = []
        if self.ai_priority_exploits is None:
            self.ai_priority_exploits = []
        if self.exploit_type_distribution is None:
            self.exploit_type_distribution = {}
        if self.platform_distribution is None:
            self.platform_distribution = {}
        if self.temporal_distribution is None:
            self.temporal_distribution = {}
    
    def get_high_threat_exploits(self) -> List[ExploitDBEntry]:
        """Get exploits with high threat levels"""
        return [
            exploit for exploit in self.exploits
            if exploit.ai_threat_level in [ThreatLevel.CRITICAL, ThreatLevel.HIGH]
        ]
    
    def get_remote_exploits(self) -> List[ExploitDBEntry]:
        """Get remote exploits (highest priority)"""
        return [
            exploit for exploit in self.exploits
            if exploit.is_remote_exploit()
        ]
    
    def get_verified_exploits(self) -> List[ExploitDBEntry]:
        """Get verified exploits"""
        return [
            exploit for exploit in self.exploits
            if exploit.is_verified_exploit()
        ]
    
    def get_recent_exploits(self, days: int = 365) -> List[ExploitDBEntry]:
        """Get recently published exploits"""
        cutoff_date = datetime.utcnow() - timedelta(days=days)
        return [
            exploit for exploit in self.exploits
            if exploit.date_published and exploit.date_published > cutoff_date
        ]
    
    def calculate_statistics(self):
        """Calculate statistical distributions"""
        # Exploit type distribution
        type_counts = {}
        for exploit in self.exploits:
            exploit_type = exploit.exploit_type.value
            type_counts[exploit_type] = type_counts.get(exploit_type, 0) + 1
        self.exploit_type_distribution = type_counts
        
        # Platform distribution
        platform_counts = {}
        for exploit in self.exploits:
            platform = exploit.platform.value
            platform_counts[platform] = platform_counts.get(platform, 0) + 1
        self.platform_distribution = platform_counts
        
        # Temporal distribution
        year_counts = {}
        for exploit in self.exploits:
            if exploit.date_published:
                year = exploit.date_published.year
                year_counts[str(year)] = year_counts.get(str(year), 0) + 1
        self.temporal_distribution = year_counts
        
        # Verification rate
        verified_count = len(self.get_verified_exploits())
        self.verification_rate = verified_count / max(1, len(self.exploits))
    
    def get_threat_summary(self) -> Dict[str, Any]:
        """Get comprehensive threat summary"""
        high_threat = self.get_high_threat_exploits()
        remote = self.get_remote_exploits()
        verified = self.get_verified_exploits()
        recent = self.get_recent_exploits()
        
        return {
            "target_package": self.target_package,
            "total_exploits": self.total_exploits,
            "high_threat_count": len(high_threat),
            "remote_exploit_count": len(remote),
            "verified_exploit_count": len(verified),
            "recent_exploit_count": len(recent),
            "verification_rate": self.verification_rate,
            "overall_threat_level": self.ai_overall_threat_level.value if self.ai_overall_threat_level else "unknown",
            "threat_landscape": self.ai_threat_landscape,
            "priority_exploits": self.ai_priority_exploits,
            "attack_patterns": self.ai_attack_patterns,
            "defensive_recommendations": self.ai_defensive_recommendations,
            "exploit_type_distribution": self.exploit_type_distribution,
            "platform_distribution": self.platform_distribution
        }


@dataclass
class ExploitDBSearchContext:
    """
    Context for AI-enhanced Exploit-DB searches.
    """
    package_name: str
    search_terms: List[str] = None
    include_unverified: bool = True
    max_results: int = 100
    date_range: Optional[tuple] = None  # (start_date, end_date)
    
    # AI enhancement options
    ai_threat_analysis: bool = True
    ai_relevance_filtering: bool = True
    ai_priority_scoring: bool = True
    
    def __post_init__(self):
        if self.search_terms is None:
            self.search_terms = []
    
    def get_search_query(self) -> str:
        """Generate search query string"""
        terms = [self.package_name] + self.search_terms
        return " ".join(terms)
    
    def to_prompt_context(self) -> Dict[str, Any]:
        """Convert to context suitable for AI prompts"""
        return {
            "package_name": self.package_name,
            "search_terms": self.search_terms,
            "include_unverified": self.include_unverified,
            "max_results": self.max_results,
            "date_range": f"{self.date_range[0]} to {self.date_range[1]}" if self.date_range else "All time",
            "ai_analysis_enabled": self.ai_threat_analysis
        }